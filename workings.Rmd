---
title: "Kaggle - Quora Question Pairs"
output:
  html_notebook:
    toc: TRUE
    toc_float: TRUE
---

# Introduction

Click [here](https://www.kaggle.com/c/quora-question-pairs)

# Load libraries
```{r}
library(magrittr)
library(ggplot2)
```


# Dataset

Load train set:
```{r}
library(readr)
train.df <- read_csv("./data/train.csv", 
    col_types = cols(is_duplicate = col_logical()))

train.df %<>%
  dplyr::mutate(type = factor("train", c("train", "test")))

summary(train.df)

```
```{r}
train.df %>%
  dplyr::select(question1, question2) %>%
  head
```

View target label's distribution:
```{r}
train.df %>%
  dplyr::select(is_duplicate) %>%
  dplyr::group_by(is_duplicate) %>%
  dplyr::summarise(count = n()) %>%
  dplyr::mutate(count = count/sum(count))
```

Load test set:
```{r}

test.df <- read_csv("./data/test.csv")

test.df %<>%
  dplyr::mutate(type = factor("test", c("train", "test")))

summary(test.df)

```

```{r}
test.df %>%
  dplyr::select(question1, question2) %>%
  head
```

For the purpose of OPIM 5671, do not work on test since it is too time consuming to engineer features for 2 million questions.


# Data preprocessing

## Raw text

Create a two-column data frame, question_id and question:

```{r}
raw.df <- train.df %>%
  dplyr::select(qid1, question1) %>%
  magrittr::set_colnames(c("question_id", "question")) %>%
  dplyr::bind_rows(train.df %>%
                     dplyr::select(qid2, question2) %>%
                     magrittr::set_colnames(c("question_id", "question"))) %>%
  dplyr::mutate(question_id = as.character(paste(question_id, "train", sep = "-")))

```


Save `raw.df` (only unique question id and question pairs!):
```{r}
raw.df %>%
  dplyr::distinct() %>%
  write.csv("./data/raw_opim5671.csv", row.names = F)
```

Also, fill missing questions in `train.df` and save it for feature engineering:
```{r}

train.df %>%
  # replace missing questions with some dummy string to avoid errors duing feature engineering
  dplyr::mutate(
  question1 = dplyr::if_else(is.na(question1), "NaN!", question1),
  question2 = dplyr::if_else(is.na(question2), "NaN!", question2)
  )  %>%
  write.csv("./data/consol_with_custid_opim5671.csv", row.names = F)
```


## Tidy text
Load the raw text:
```{r}
if (!exists("raw.df")) raw.df <- read.csv("./data/raw_opim5671.csv", stringsAsFactors = F)
summary(raw.df)
```

Tidy the questions:
```{r}
tidy.df <- raw.df %>%
  dplyr::sample_frac(5/100) %>%
  tidytext::unnest_tokens(word, question)

summary(tidy.df)
```


# Feature Engineering

## Number of words

Work off a sample of `raw.df`:
```{r}
sample.raw.df <- raw.df #%>%
 # dplyr::sample_frac(1/100)

dim(sample.raw.df)

```

Create a cluster of 4-nodes and set it as the default:
```{r}
my.cluster <- multidplyr::create_cluster(4)
multidplyr::set_default_cluster(my.cluster)

my.cluster
```

Load the required libraries into the cluster:
```{r}
multidplyr::cluster_library(my.cluster, c("magrittr"))
```

Group the data by question id and load it into the cluster :
```{r}
parts.df <- sample.raw.df %>%
  multidplyr::partition(question_id)

parts.df
```

Compute the number of words in each question:
```{r}
system.time(
  word.count.df <- parts.df %>%
   dplyr::do(
    tidytext::unnest_tokens(., word, question) %>%
      dplyr::count(question_id)
  ) %>%
  dplyr::collect()
)

word.count.df
```
```{r}
word.count.df %>%
  write.csv("./data/raw_with_word_count.csv", row.names = F)
```

Questions in `word.count.df` but not in `raw.df`:
```{r}
y <- word.count.df %>%
  dplyr::anti_join(sample.raw.df, by = c("question_id"))

y
```

Questions in `raw.df` but not in `word.count.df`:
```{r}
x <- sample.raw.df %>%
  dplyr::anti_join(word.count.df, by = c("question_id"))

x
```

Load the word count data frame:
```{r}
if (!exists("word.count.df"))
  word.count.df <- read.csv("./data/raw_with_word_count.csv", stringsAsFactors = F
  )
summary(word.count.df)
```

## Count nouns and Wh- words

Script is in `count_noun_wh.R`.

# Model building

Load the consolidated data set if it is not already loaded:
```{r}
if (!exists("consol.df"))
  library(readr)
  consol.df <- read_csv("./data/consol_with_custid_opim5671.csv",
  col_types = cols(is_duplicate = col_logical())
  )
```

```{r}
head(train.df)
```

```{r}
summary(consol.df)
```


## Consolidate features

### Word count

Import the word count file:
```{r}
word.count.df <- read.csv("./data/raw_with_word_count.csv", stringsAsFactors = F)

head(word.count.df)
```

For the purpose of OPIM 5671, filter the file to remove test set and adjust the question id:
```{r}

word.count.df %<>%
  dplyr::filter(!stringr::str_detect(question_id, "test")) %>%
  dplyr::mutate(question_id = as.integer(stringr::str_replace(question_id, "(\\d*)-train", "\\1"))) 
```

Get the word count for question 1 and question 2:
```{r}
consol.df %<>%
  dplyr::left_join(word.count.df, by = c("qid1" = "question_id")) %>%
  dplyr::rename(q1.wc = n ) %>%
  dplyr::left_join(word.count.df, by = c("qid2" = "question_id")) %>%
  dplyr::rename(q2.wc = n)

consol.df %>%
  dplyr::select(q1.wc, q2.wc) %>%
  summary
```

The NAs are "questions" consisting of punctuations or unicode only, so set them to zero:
```{r}
consol.df %<>%
  dplyr::mutate(q1.wc = dplyr::if_else(is.na(q1.wc), 0L, q1.wc),
                q2.wc = dplyr::if_else(is.na(q2.wc), 0L, q2.wc))

```

Compute the difference in word count:

```{r}
consol.df %<>%
  dplyr::mutate(diff.wc = abs(q1.wc - q2.wc))

consol.df %>%
  dplyr::select(q1.wc:diff.wc) %>%
  summary
```

Vizualize distribution of word counts among the duplicates:
```{r}
consol.df %>%
  ggplot(aes(x = is_duplicate, y = diff.wc)) +
  geom_boxplot()
```

